{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2GPe8hlK5MxxRQEEjmLTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdrezende1/perceptron/blob/main/ml_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSuk-K5wH-Wp",
        "outputId": "f3b95cf5-f1f7-438d-d1e8-2b083e3bc005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A amostra de teste [0.75, 0.9] foi classificada como: -1\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# ---\n",
        "# Implementação Perceptron\n",
        "# ---\n",
        "import sys\n",
        "import random\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Classe que representa um Perceptron de camada única.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, amostras, saidas, taxa_aprendizado=0.1, epocas=1000, limiar=1):\n",
        "        \"\"\"\n",
        "        Método construtor da classe Perceptron.\n",
        "\n",
        "        Parâmetros:\n",
        "        amostras (list): Lista de listas com os dados de entrada para o treinamento.\n",
        "        saidas (list): Lista com as saídas esperadas para cada amostra.\n",
        "        taxa_aprendizado (float): Taxa de aprendizado da rede.\n",
        "        epocas (int): Número máximo de épocas para o treinamento.\n",
        "        limiar (int): Valor do limiar (bias) adicionado a cada amostra.\n",
        "        \"\"\"\n",
        "        self.amostras = amostras\n",
        "        self.saidas = saidas\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "        self.epocas = epocas\n",
        "        self.limiar = limiar\n",
        "        self.n_amostras = len(amostras)  # Número de amostras (linhas)\n",
        "        self.n_atributos = len(amostras[0])  # Número de atributos por amostra\n",
        "        self.pesos = []\n",
        "\n",
        "    def treinar(self):\n",
        "        \"\"\"\n",
        "        Realiza o treinamento do Perceptron.\n",
        "        \"\"\"\n",
        "        # Inicializa os pesos com valores aleatórios entre 0 e 1,\n",
        "        # incluindo o peso para o bias (+1 atributo).\n",
        "        for i in range(self.n_atributos + 1):\n",
        "            self.pesos.append(random.random())\n",
        "\n",
        "        # Adiciona o valor do limiar (bias) no início de cada amostra de entrada\n",
        "        # para que ele possa ser multiplicado por um peso.\n",
        "        for amostra in self.amostras:\n",
        "            amostra.insert(0, self.limiar)\n",
        "\n",
        "        n_epocas = 0\n",
        "        while True:\n",
        "            erro_total = False\n",
        "            for i in range(self.n_amostras):\n",
        "                # Calcula o potencial de ativação (somatório do produto dos pesos pelas amostras)\n",
        "                u = 0\n",
        "                for j in range(self.n_atributos + 1):\n",
        "                    u += self.pesos[j] * self.amostras[i][j]\n",
        "\n",
        "                # Aplica a função de ativação (função sinal)\n",
        "                y = self.sinal(u)\n",
        "\n",
        "                # Verifica se a saída da rede é diferente da saída desejada\n",
        "                if y != self.saidas[i]:\n",
        "                    erro = self.saidas[i] - y\n",
        "\n",
        "                    # Ajusta os pesos de acordo com o erro e a taxa de aprendizado\n",
        "                    for j in range(self.n_atributos + 1):\n",
        "                        self.pesos[j] = self.pesos[j] + self.taxa_aprendizado * erro * self.amostras[i][j]\n",
        "\n",
        "                    erro_total = True  # Indica que houve erro na época atual\n",
        "\n",
        "            n_epocas += 1\n",
        "\n",
        "            # Critérios de parada: se não houve erro ou se o número máximo de épocas foi atingido.\n",
        "            if not erro_total or n_epocas > self.epocas:\n",
        "                break\n",
        "\n",
        "    def teste(self, amostra):\n",
        "        \"\"\"\n",
        "        Testa uma nova amostra no Perceptron treinado.\n",
        "\n",
        "        Parâmetros:\n",
        "        amostra (list): Lista com os dados de entrada para o teste.\n",
        "        \"\"\"\n",
        "        # Cria uma cópia da amostra para não modificar a original\n",
        "        amostra_teste = amostra[:]\n",
        "        # Adiciona o limiar para o cálculo\n",
        "        amostra_teste.insert(0, self.limiar)\n",
        "\n",
        "        # Calcula o potencial de ativação para a amostra de teste\n",
        "        u = 0\n",
        "        for i in range(self.n_atributos + 1):\n",
        "            u += self.pesos[i] * amostra_teste[i]\n",
        "\n",
        "        # Aplica a função de ativação\n",
        "        y = self.sinal(u)\n",
        "\n",
        "        print(f'A amostra de teste {amostra} foi classificada como: {y}')\n",
        "\n",
        "    def sinal(self, u):\n",
        "        \"\"\"\n",
        "        Função de ativação sinal.\n",
        "        Retorna 1 se o valor de u for maior ou igual a 0, e -1 caso contrário.\n",
        "        \"\"\"\n",
        "        return 1 if u >= 0 else -1\n",
        "\n",
        "# ---\n",
        "# Exemplo de uso\n",
        "# ---\n",
        "\n",
        "# Amostras (entrada e saída) para treinamento\n",
        "amostras = [\n",
        "    [0.72, 0.82], [0.91, -0.69], [0.46, 0.80], [0.03, 0.93],\n",
        "    [0.12, 0.25], [0.96, 0.47], [0.8, -0.75], [0.46, 0.98],\n",
        "    [0.66, 0.24], [0.72, -0.15], [0.35, 0.01], [-0.16, 0.84],\n",
        "    [-0.04, 0.68], [-0.11, 0.1], [0.31, -0.96], [0.0, -0.26],\n",
        "    [-0.43, -0.65], [0.57, -0.97], [-0.47, -0.03], [-0.72, -0.64],\n",
        "    [-0.57, 0.15], [-0.25, -0.43], [0.47, -0.88], [-0.12, -0.9],\n",
        "    [-0.58, 0.62], [-0.48, 0.05], [-0.79, -0.92], [-0.42, -0.09],\n",
        "    [-0.76, 0.65], [-0.77, -0.76]\n",
        "]\n",
        "saidas = [\n",
        "    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
        "]\n",
        "\n",
        "# Chamar a classe e fazer o treinamento das amostras\n",
        "rede = Perceptron(amostras, saidas)\n",
        "rede.treinar()\n",
        "\n",
        "# Entrando com uma amostra para teste\n",
        "# O código original testa [0.46, 0.80], que é uma amostra já usada.\n",
        "# Para um teste mais representativo, podemos usar uma amostra nova.\n",
        "amostra_teste = [0.75, 0.90] # Amostra que a rede não viu\n",
        "rede.teste(amostra_teste)\n",
        "\n",
        "# Fim do perceptron"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KdtPYEcIBOt"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}